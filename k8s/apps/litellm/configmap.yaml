apiVersion: v1
kind: ConfigMap
metadata:
  name: litellm-config
  namespace: litellm
  labels:
    app.kubernetes.io/name: litellm
    app.kubernetes.io/part-of: ai-gateway
data:
  proxy_server_config.yaml: |
    # ──────────────────────────────────────────────────────────
    # LiteLLM Proxy Configuration
    # Docs: https://docs.litellm.ai/docs/proxy/configs
    # ──────────────────────────────────────────────────────────

    model_list:
      # ── OpenAI ─────────────────────────────────────────────
      - model_name: gpt-4o
        litellm_params:
          model: openai/gpt-4o
          api_key: os.environ/OPENAI_API_KEY

      - model_name: gpt-4o-mini
        litellm_params:
          model: openai/gpt-4o-mini
          api_key: os.environ/OPENAI_API_KEY

      # ── Anthropic ──────────────────────────────────────────
      - model_name: claude-sonnet
        litellm_params:
          model: anthropic/claude-sonnet-4-20250514
          api_key: os.environ/ANTHROPIC_API_KEY

      - model_name: claude-haiku
        litellm_params:
          model: anthropic/claude-3-5-haiku-20241022
          api_key: os.environ/ANTHROPIC_API_KEY

      # Add more providers (Azure, Bedrock, Vertex, etc.) below
      # - model_name: ...
      #   litellm_params:
      #     model: ...
      #     api_key: os.environ/...

    litellm_settings:
      drop_params: true
      set_verbose: false
      cache: true
      cache_params:
        type: redis
        host: os.environ/REDIS_HOST
        port: os.environ/REDIS_PORT

    general_settings:
      master_key: os.environ/LITELLM_MASTER_KEY
      database_url: os.environ/DATABASE_URL
      alerting:
        - slack
      alerting_threshold: 300       # seconds before alert on slow responses
